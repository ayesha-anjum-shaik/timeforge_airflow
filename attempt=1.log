(airflow_env) ayeshashaik@Ayeshashaik:~/airflow/logs/dag_id=csv_to_postgres/run_id=manual__2023-04-30T07:08:23.955644+00:00/task_id=task_1$ cat attempt\=1.log
[2023-04-30T12:38:26.938+0530] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: csv_to_postgres.task_1 manual__2023-04-30T07:08:23.955644+00:00 [queued]>
[2023-04-30T12:38:26.943+0530] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: csv_to_postgres.task_1 manual__2023-04-30T07:08:23.955644+00:00 [queued]>
[2023-04-30T12:38:26.944+0530] {taskinstance.py:1288} INFO -
--------------------------------------------------------------------------------
[2023-04-30T12:38:26.944+0530] {taskinstance.py:1289} INFO - Starting attempt 1 of 2
[2023-04-30T12:38:26.944+0530] {taskinstance.py:1290} INFO -
--------------------------------------------------------------------------------
[2023-04-30T12:38:26.959+0530] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): task_1> on 2023-04-30 07:08:23.955644+00:00
[2023-04-30T12:38:26.966+0530] {standard_task_runner.py:55} INFO - Started process 16607 to run task
[2023-04-30T12:38:26.969+0530] {standard_task_runner.py:82} INFO - Running: ['airflow', 'tasks', 'run', 'csv_to_postgres', 'task_1', 'manual__2023-04-30T07:08:23.955644+00:00', '--job-id', '20', '--raw', '--subdir', 'DAGS_FOLDER/projectcode.py', '--cfg-path', '/tmp/tmppeuo6vs1']
[2023-04-30T12:38:26.971+0530] {standard_task_runner.py:83} INFO - Job 20: Subtask task_1
[2023-04-30T12:38:27.004+0530] {task_command.py:389} INFO - Running <TaskInstance: csv_to_postgres.task_1 manual__2023-04-30T07:08:23.955644+00:00 [running]> on host ayeshashaik.localdomain
[2023-04-30T12:38:27.040+0530] {taskinstance.py:1516} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=ayeshashaik0727@gmail.com
AIRFLOW_CTX_DAG_OWNER=ayeshashaik
AIRFLOW_CTX_DAG_ID=csv_to_postgres
AIRFLOW_CTX_TASK_ID=task_1
AIRFLOW_CTX_EXECUTION_DATE=2023-04-30T07:08:23.955644+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-04-30T07:08:23.955644+00:00
[2023-04-30T12:38:27.053+0530] {logging_mixin.py:137} WARNING - /home/ayeshashaik/airflow/dags/projectcode.py:52 UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
[2023-04-30T12:38:27.073+0530] {logging_mixin.py:137} INFO -    location_id  belongs_to   totala
0        19481  2011-01-01  7726.57
1        19481  2011-01-02  6372.92
2        19481  2011-01-03  9316.48
3        19481  2011-01-04  7699.63
4        19481  2011-01-05  8130.77
[2023-04-30T12:38:27.075+0530] {logging_mixin.py:137} WARNING - /home/ayeshashaik/airflow/dags/projectcode.py:61 SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
[2023-04-30T12:38:42.062+0530] {logging_mixin.py:137} INFO - Selected model parameters: p=0, d=0, q=1, P=0, D=0, Q=0, m=12
[2023-04-30T12:38:42.068+0530] {python.py:177} INFO - Done. Returned value was: None
[2023-04-30T12:38:42.096+0530] {taskinstance.py:1327} INFO - Marking task as SUCCESS. dag_id=csv_to_postgres, task_id=task_1, execution_date=20230430T070823, start_date=20230430T070826, end_date=20230430T070842
[2023-04-30T12:38:42.145+0530] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-04-30T12:38:42.152+0530] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check